<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>



  <link href='//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>




  <meta name="keywords" content="logs," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="nothing">
<meta property="og:type" content="article">
<meta property="og:title" content="some logs">
<meta property="og:url" content="http://yoursite.com/2015/10/17/log_torch/index.html">
<meta property="og:site_name" content="XXXH">
<meta property="og:description" content="nothing">
<meta property="og:updated_time" content="2015-12-07T19:31:30.715Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="some logs">
<meta name="twitter:description" content="nothing">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    sidebar: 'post'
  };
</script>



  <title> some logs | XXXH </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  






  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">XXXH</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            Tags
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              some logs
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2015-10-17T21:44:43+02:00" content="2015-10-17">
            2015-10-17
          </time>
        </span>

        

        
          
        
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><p>nothing<br><a id="more"></a></p>
<p>installing file without sodu:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget ftp:<span class="comment">//ftp.cwru.edu/pub/bash/readline-6.3.tar.gz</span></span><br><span class="line">http:<span class="comment">//download.zeromq.org/zeromq-4.0.3.tar.gz</span></span><br><span class="line">tar xfz zeromq-<span class="number">4.0</span><span class="number">.3</span>.tar.gz</span><br><span class="line">cd zeromq-<span class="number">4.0</span><span class="number">.3</span>/</span><br><span class="line">./configure --prefix=~/local</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># <span class="operator"><span class="keyword">Install</span> zmq <span class="keyword">library</span></span><br><span class="line">#<span class="comment">-------------------</span></span><br><span class="line"><span class="keyword">export</span> LD_LIBRARY_PATH=~/<span class="keyword">local</span>/lib/</span><br><span class="line"><span class="keyword">export</span> PKG_CONFIG_PATH=~/<span class="keyword">local</span>/lib/pkgconfig/</span><br><span class="line"><span class="keyword">export</span> C_INCLUDE_PATH=$C_INCLUDE_PATH:~/usr/<span class="keyword">include</span></span><br><span class="line"><span class="keyword">export</span> CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:~/usr/<span class="keyword">include</span></span><br><span class="line"><span class="keyword">When</span> building packages, <span class="keyword">use</span> ./configure <span class="comment">--prefix=/home/&lt;username&gt;/usr</span></span><br><span class="line"></span><br><span class="line"># <span class="keyword">in</span> <span class="keyword">some</span> OS<span class="string">'s you may need this too:</span><br><span class="line">export CXXFLAGS="-I ~/local/include" // solve the problem of headfile not found</span><br><span class="line"></span><br><span class="line">export LDFLAGS="-L ~/local/lib/ -Wl,-rpath=~/local/lib/"</span></span></span><br></pre></td></tr></table></figure>
<p>LD_LIBRARY_PATH </p>
<p><code>source .bashrc</code> after setting the path, update the file</p>
<p>git clone <a href="https://github.com/facebook/iTorch.git" target="_blank" rel="external">https://github.com/facebook/iTorch.git</a><br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// install zmq</span></span><br><span class="line"> luarocks install lzmq ZMQ_DIR=~<span class="regexp">/.npm-packages/</span>etc<span class="regexp">/node_modules/</span>zmq<span class="regexp">/windows/</span></span><br><span class="line"><span class="comment">// install ipython</span></span><br><span class="line"> luarocks make --local ZMQ_DIR=~<span class="regexp">/.npm-packages/</span>etc<span class="regexp">/node_modules/</span>zmq<span class="regexp">/windows/</span></span><br><span class="line"></span><br><span class="line"> luarocks install --local loadcaffe</span><br></pre></td></tr></table></figure></p>
<h1 id="neural_style">neural_style</h1><p> h neural_style.lua -style_image ./examples/inputs/the_scream.jpg -content_image ./examples/inputs/frida_kahlo.jpg </p>
<p>apt-get install p7zip-full<br>dpkg -i –force-not-root –root=$HOME package.deb</p>
<p>PATH=$PATH:~/Support/7z/p7zip-9.20.1~dfsg.1/bin</p>
<p>wget -x –load-cookies cookies.txt <a href="https://www.kaggle.com/c/cifar-10/download/test.7z" target="_blank" rel="external">https://www.kaggle.com/c/cifar-10/download/test.7z</a></p>
<p>in lua add package path<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package<span class="class">.path</span> = package<span class="class">.path</span> .. <span class="string">";C:\\Users\\Me\\MyLuaProject"</span></span><br></pre></td></tr></table></figure></p>
<h1 id="count_the_number_of_file">count the number of file</h1><p>ls -1 targetdir | wc -l<br>ls -1 . | wc -l</p>
<h1 id="cifar-torch">cifar.torch</h1><p><a href="https://github.com/szagoruyko/cifar.torch" target="_blank" rel="external">https://github.com/szagoruyko/cifar.torch</a></p>
<h2 id="data_processing:">data processing:</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">OMP_NUM_THREADS=<span class="number">2</span> </span><br><span class="line"><span class="tag">th</span> -<span class="tag">i</span> provider<span class="class">.lua</span></span><br><span class="line">provider = <span class="function"><span class="title">Provider</span><span class="params">()</span></span></span><br><span class="line">provider:<span class="function"><span class="title">normalize</span><span class="params">()</span></span></span><br><span class="line">torch.<span class="function"><span class="title">save</span><span class="params">(<span class="string">'provider.t7'</span>,provider)</span></span></span><br></pre></td></tr></table></figure>
<h2 id="training">training</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> </span><br><span class="line"><span class="tag">th</span> train<span class="class">.lua</span> --model vgg_bn_drop_simple -s logs/vgg_simple</span><br><span class="line"><span class="tag">th</span> train<span class="class">.lua</span> --model cnnft_net -s logs/<span class="number">0112</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">debug: 	</span><br><span class="line">torch.FloatTensor	</span><br><span class="line">torch.FloatTensor	</span><br><span class="line">/home/xizeng/torch/<span class="operator"><span class="keyword">install</span>/<span class="keyword">bin</span>/luajit: ...xizeng/.luarocks/<span class="keyword">share</span>/lua/<span class="number">5.1</span>/nn/SpatialConvolution.lua:<span class="number">100</span>: bad argument #<span class="number">1</span> (<span class="keyword">field</span> finput <span class="keyword">is</span> <span class="keyword">not</span> a torch.FloatTensor)</span><br><span class="line">stack traceback:</span><br><span class="line">	[<span class="keyword">C</span>]: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'SpatialConvolutionMM_updateOutput'</span></span><br><span class="line">	...xizeng/.luarocks/<span class="keyword">share</span>/lua/<span class="number">5.1</span>/nn/SpatialConvolution.lua:<span class="number">100</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'updateOutput'</span></span><br><span class="line">	/home/xizeng/.luarocks/<span class="keyword">share</span>/lua/<span class="number">5.1</span>/nn/<span class="keyword">Sequential</span>.lua:<span class="number">44</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'updateOutput'</span></span><br><span class="line">	/home/xizeng/.luarocks/<span class="keyword">share</span>/lua/<span class="number">5.1</span>/nn/<span class="keyword">Sequential</span>.lua:<span class="number">44</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'forward'</span></span><br><span class="line">	train.lua:<span class="number">110</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'opfunc'</span></span><br><span class="line">	/home/xizeng/torch/<span class="keyword">install</span>/<span class="keyword">share</span>/lua/<span class="number">5.1</span>/optim/sgd.lua:<span class="number">44</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'sgd'</span></span><br><span class="line">	train.lua:<span class="number">119</span>: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'train'</span></span><br><span class="line">	train.lua:<span class="number">194</span>: <span class="keyword">in</span> <span class="keyword">main</span> <span class="keyword">chunk</span></span><br><span class="line">	[<span class="keyword">C</span>]: <span class="keyword">in</span> <span class="keyword">function</span> <span class="string">'dofile'</span></span><br><span class="line">	...zeng/torch/<span class="keyword">install</span>/lib/luarocks/rocks/trepl/scm-<span class="number">1</span>/<span class="keyword">bin</span>/th:<span class="number">145</span>: <span class="keyword">in</span> <span class="keyword">main</span> <span class="keyword">chunk</span></span><br><span class="line">	[<span class="keyword">C</span>]: <span class="keyword">at</span> <span class="number">0x00405ab0</span></span></span><br></pre></td></tr></table></figure>
<p>solv: cast the <code>inputs</code> <code>model</code> <code>criterion</code> into Float by<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = model: <span class="function"><span class="title">float</span><span class="params">()</span></span></span><br><span class="line">inputs = inputs: <span class="function"><span class="title">float</span><span class="params">()</span></span></span><br><span class="line">criterion = inputs: <span class="function"><span class="title">float</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure></p>
<p>untar：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf public_html-<span class="number">14</span>-<span class="number">09</span>-<span class="number">12.</span>tar</span><br></pre></td></tr></table></figure></p>
<h2 id="screen_command">screen command</h2><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">#screen &lt;run something&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// come back:</span></span><br><span class="line"><span class="preprocessor"># screen -ls</span></span><br><span class="line"><span class="preprocessor"># screen -r seq</span></span><br><span class="line"><span class="comment">// screen接收以C-a开始的命令</span></span><br></pre></td></tr></table></figure>
<p>layer1 Conv1:<br>kernel ：32 ，kernel size ： 5 , activation ： relu ，dropout ： 0.25<br>layer2 Conv2:<br>kernel: 32,kernel size: 5, activation ： relu ，dropout ： 0.25<br>layer3 MaxPooling1: poolsize:2<br>layer4 Conv3:<br>kernel: 64,kernel size: 3, activation ： relu ，dropout ： 0.25<br>layer5 MaxPooling2: poolsize:2<br>layer6: full connect 512 ，activation ：tanh<br>layer7: softmax</p>
<p><a href="http://www.bubuko.com/infodetail-1066303.html" target="_blank" rel="external">http://www.bubuko.com/infodetail-1066303.html</a></p>
<p>##<br>find library<br>ldconfig -p | grep libjpeg</p>
<h2 id="environment_variable_affecting_GCC">environment variable affecting GCC</h2><p><a href="https://gcc.gnu.org/onlinedocs/gcc/Environment-Variables.html" target="_blank" rel="external">https://gcc.gnu.org/onlinedocs/gcc/Environment-Variables.html</a></p>
<p>LD_LIBRARY_PATH for own shared object file </p>
<p><a href="http://www.cs.swarthmore.edu/~newhall/unixhelp/howto_C_libraries.html" target="_blank" rel="external">http://www.cs.swarthmore.edu/~newhall/unixhelp/howto_C_libraries.html</a></p>
<h2 id="setting_shell_configure">setting shell configure</h2><p>in $HOME/.profile run<br>. /home/x…. activate <code>file</code></p>
<p>in which export the environment variable and append new variable to it </p>
<h2 id="install_blas">install blas</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv make<span class="class">.inc</span><span class="class">.example</span> make<span class="class">.inc</span></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line">gfortran: error: ../../librefblas<span class="class">.a</span>: No such file or directory</span><br></pre></td></tr></table></figure>
<p>reason: in Makefile, the installation of blaslib is comment, uncomment it will can solve</p>
<h2 id="install_torch_without_sodu">install torch without sodu</h2><p>./install.sh PREFIX=/home/usrname/local</p>
<p>install lapack and openblas<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> openblas, <span class="built_in">set</span> NO_LAPACK=<span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CMAKE_LIBRARY_PATH=/path/<span class="keyword">to</span>/lapack-<span class="number">3.4</span>.<span class="number">0</span>:<span class="variable">$CMAKE</span>_LIBRARY_PATH </span><br><span class="line"></span><br><span class="line">luarocks install torch</span><br></pre></td></tr></table></figure>
<h1 id="ERROR_lapack">ERROR lapack</h1><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">u/torch/install/bin/<span class="symbol">luajit:</span> syev <span class="symbol">:</span> <span class="constant">Lapack</span> library not found in compile time</span><br><span class="line"> at /tmp/luarocks_torch-scm-<span class="number">1</span>-<span class="number">5326</span>/torch7/<span class="class"><span class="keyword">lib</span>/<span class="title">TH</span>/<span class="title">generic</span>/<span class="title">THLapack</span>.<span class="title">c</span>:68</span></span><br><span class="line">stack <span class="symbol">traceback:</span></span><br><span class="line">        [<span class="constant">C</span>]<span class="symbol">:</span> at <span class="number">0x7ff39fdc7930</span></span><br><span class="line">        [<span class="constant">C</span>]<span class="symbol">:</span> in function <span class="string">'symeig'</span></span><br><span class="line">        /home/ee532_stu/cifar10_handsome/<span class="class"><span class="keyword">lib</span>/<span class="title">preprocessing</span>.<span class="title">lua</span>:16: <span class="title">in</span> <span class="title">function</span> '<span class="title">pcacov</span>'</span></span><br><span class="line">        /home/ee532_stu/cifar10_handsome/<span class="class"><span class="keyword">lib</span>/<span class="title">preprocessing</span>.<span class="title">lua</span>:32: <span class="title">in</span> <span class="title">function</span> '<span class="title">zca_whiten</span>'</span></span><br><span class="line">        /home/ee532_stu/cifar10_handsome/<span class="class"><span class="keyword">lib</span>/<span class="title">preprocessing</span>.<span class="title">lua</span>:74: <span class="title">in</span> <span class="title">function</span> '<span class="title">zca</span>'</span></span><br><span class="line">        /home/ee532_stu/cifar10_handsome/<span class="class"><span class="keyword">lib</span>/<span class="title">preprocessing</span>.<span class="title">lua</span>:92: <span class="title">in</span> <span class="title">function</span> '<span class="title">preprocessing</span>'</span></span><br><span class="line">        validate.<span class="symbol">lua:</span><span class="number">63</span><span class="symbol">:</span> in function <span class="string">'validation'</span></span><br><span class="line">        validate.<span class="symbol">lua:</span><span class="number">85</span><span class="symbol">:</span> in main chunk</span><br><span class="line">        [<span class="constant">C</span>]<span class="symbol">:</span> in function <span class="string">'dofile'</span></span><br><span class="line">        ..._stu/torch/install/<span class="class"><span class="keyword">lib</span>/<span class="title">luarocks</span>/<span class="title">rocks</span>/<span class="title">trepl</span>/<span class="title">scm</span>-1/<span class="title">bin</span>/<span class="title">th</span>:131: <span class="title">in</span> <span class="title">main</span> <span class="title">chunk</span></span></span><br><span class="line">        [<span class="constant">C</span>]<span class="symbol">:</span> at <span class="number">0x00406670</span></span><br></pre></td></tr></table></figure>
<p>solve: install openblas and lapack, re install torch</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">INSTALL</span> OPENBLAS:</span><br><span class="line"></span><br><span class="line">make NO_LAPACK=<span class="number">0</span> USE_OPENMP=<span class="number">1</span></span><br><span class="line">make PREFIX=/<span class="keyword">PATH</span>/<span class="keyword">TO</span>/OPENBLAS <span class="keyword">install</span></span></span><br></pre></td></tr></table></figure>
<h2 id="error：">error：</h2><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">OpenBLAS Warning : Detect OpenMP <span class="keyword">Loop</span> <span class="keyword">and</span> this application may hang. Please rebuild the <span class="keyword">library</span> <span class="keyword">with</span> USE_OPENMP=<span class="number">1</span> option.</span><br><span class="line"><span class="comment">// when running train.lua</span></span><br></pre></td></tr></table></figure>
<p>solution: export OMP_NUM_THREADS=1</p>
<h2 id="error:">error:</h2><p>kaggle: size mismatch<br>cifar-10: cur-target less than 0</p>
<h2 id="torch_syntax">torch syntax</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- <span class="keyword">for</span> torch<span class="class">.tensor</span></span><br><span class="line"><span class="tag">a</span>:<span class="function"><span class="title">size</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line">-- nn<span class="class">.Sequential</span>, type: &lt;table&gt;</span><br><span class="line"><span class="tag">a</span> = medel<span class="class">.modules</span>[<span class="number">1</span>]</span><br><span class="line"><span class="comment">// if more than one module in the image</span></span><br><span class="line"></span><br><span class="line"><span class="tag">a</span><span class="class">.output</span> <span class="comment">// print the output of layer 1</span></span><br></pre></td></tr></table></figure>
<h2 id="parallel_table:">parallel table:</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">th&gt; para2 = nn.ParallelTable()</span><br><span class="line">                                                                      [<span class="number">0.0002</span>s]	</span><br><span class="line">th&gt; para2</span><br><span class="line">nn.ParallelTable &#123;</span><br><span class="line">  input</span><br><span class="line">     ... -&gt; output</span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0001</span>s]	</span><br><span class="line">th&gt; para2:add(nn.Linear(<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">nn.ParallelTable &#123;</span><br><span class="line">  input</span><br><span class="line">    |`-&gt; (<span class="number">1</span>): nn.Linear(<span class="number">3</span> -&gt; <span class="number">1</span>)</span><br><span class="line">     ... -&gt; output</span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]	</span><br><span class="line">th&gt; para2:add(nn.Linear(<span class="number">4</span>,<span class="number">1</span>))</span><br><span class="line">nn.ParallelTable &#123;</span><br><span class="line">  input</span><br><span class="line">    |`-&gt; (<span class="number">1</span>): nn.Linear(<span class="number">3</span> -&gt; <span class="number">1</span>)</span><br><span class="line">    |`-&gt; (<span class="number">2</span>): nn.Linear(<span class="number">4</span> -&gt; <span class="number">1</span>)</span><br><span class="line">     ... -&gt; output</span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]	</span><br><span class="line">th&gt; para2:forward&#123;torch.Tensor(<span class="number">3</span>),torch.Tensor(<span class="number">4</span>)&#125;</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">1</span></span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="split_table:">split table:</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">th&gt; para3:forward(torch.Tensor(<span class="number">4</span>,<span class="number">1</span>))</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]	</span><br><span class="line">th&gt; para3:forward(torch.Tensor(<span class="number">4</span>,<span class="number">2</span>))</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0006</span>s]	</span><br><span class="line">th&gt; para3:forward(torch.Tensor(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">  <span class="number">3</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">  <span class="number">4</span> : DoubleTensor - size: <span class="number">4</span></span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]	</span><br><span class="line">th&gt; para3:forward(torch.Tensor(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">&#123;</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">3</span></span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">3</span></span><br><span class="line">  <span class="number">3</span> : DoubleTensor - size: <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0005</span>s]	</span><br><span class="line">th&gt; para3 = nn.SplitTable(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h1 id="combine:">combine:</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">mlp=nn.Sequential();       --Create a network that takes a Tensor as input</span><br><span class="line">mlp:add(nn.SplitTable(<span class="number">2</span>))</span><br><span class="line"> c=nn.ParallelTable()      --The two Tensors go through two different Linear</span><br><span class="line"> c:add(nn.Linear(<span class="number">10</span>,<span class="number">3</span>))	   --Layers in Parallel</span><br><span class="line"> c:add(nn.Linear(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">mlp:add(c)                 --Outputing a table with <span class="number">2</span> elements</span><br><span class="line"> p=nn.ParallelTable()      --These tables go through two more linear layers</span><br><span class="line"> p:add(nn.Linear(<span class="number">3</span>,<span class="number">2</span>))	   -- separately.</span><br><span class="line"> p:add(nn.Linear(<span class="number">7</span>,<span class="number">1</span>)) </span><br><span class="line">mlp:add(p) </span><br><span class="line">mlp:add(nn.JoinTable(<span class="number">1</span>))   --Finally, the tables are joined together and output. </span><br><span class="line"></span><br><span class="line">th&gt; mlp:forward(torch.Tensor(<span class="number">10</span>,<span class="number">2</span>))</span><br><span class="line">-<span class="number">0.3382</span></span><br><span class="line"> <span class="number">0.3077</span></span><br><span class="line">-<span class="number">0.1244</span></span><br><span class="line">[torch.DoubleTensor of size <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">                                                                      [<span class="number">0.0011</span>s]	</span><br><span class="line">th&gt; mlp</span><br><span class="line">nn.Sequential &#123;</span><br><span class="line">  [input -&gt; (<span class="number">1</span>) -&gt; (<span class="number">2</span>) -&gt; (<span class="number">3</span>) -&gt; (<span class="number">4</span>) -&gt; output]</span><br><span class="line">  (<span class="number">1</span>): nn.SplitTable</span><br><span class="line">  (<span class="number">2</span>): nn.ParallelTable &#123;</span><br><span class="line">    input</span><br><span class="line">      |`-&gt; (<span class="number">1</span>): nn.Linear(<span class="number">10</span> -&gt; <span class="number">3</span>)</span><br><span class="line">      |`-&gt; (<span class="number">2</span>): nn.Linear(<span class="number">10</span> -&gt; <span class="number">7</span>)</span><br><span class="line">       ... -&gt; output</span><br><span class="line">  &#125;</span><br><span class="line">  (<span class="number">3</span>): nn.ParallelTable &#123;</span><br><span class="line">    input</span><br><span class="line">      |`-&gt; (<span class="number">1</span>): nn.Linear(<span class="number">3</span> -&gt; <span class="number">2</span>)</span><br><span class="line">      |`-&gt; (<span class="number">2</span>): nn.Linear(<span class="number">7</span> -&gt; <span class="number">1</span>)</span><br><span class="line">       ... -&gt; output</span><br><span class="line">  &#125;</span><br><span class="line">  (<span class="number">4</span>): nn.JoinTable</span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]</span><br></pre></td></tr></table></figure>
<h1 id="net_operation_-_read_para_and_output">net operation - read para and output</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net ... def</span><br><span class="line"></span><br><span class="line">net:<span class="function"><span class="title">getParameters</span><span class="params">()</span></span></span><br><span class="line">net:<span class="function"><span class="title">parameters</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<h2 id="the_simplest_case:_linear_regression:">the simplest case: linear regression:</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">th&gt; linear</span><br><span class="line">nn.Linear(<span class="number">3</span> -&gt; <span class="number">1</span>)</span><br><span class="line">                                                                      [<span class="number">0.0001</span>s	</span><br><span class="line">th&gt; linear:forward(torch.Tensor(<span class="number">3</span>):fill(<span class="number">2</span>))</span><br><span class="line"> <span class="number">0.7441</span></span><br><span class="line">[torch.DoubleTensor of size <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">                                                                      [<span class="number">0.0005</span>s]	</span><br><span class="line">th&gt; linear:parameters()</span><br><span class="line">&#123; -- parameters</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">1</span>x3</span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">&#123; -- gradParameters</span><br><span class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">1</span>x3 -- gradWeights</span><br><span class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">1</span> -- gradBias</span><br><span class="line">&#125;</span><br><span class="line">                                                                      [<span class="number">0.0004</span>s]	</span><br><span class="line">th&gt; linear:getParameters()</span><br><span class="line">-- flatten parameters:</span><br><span class="line">-<span class="number">0.1055</span></span><br><span class="line"> <span class="number">0.1763</span></span><br><span class="line"> <span class="number">0.1545</span></span><br><span class="line"> <span class="number">0.2935</span></span><br><span class="line">[torch.DoubleTensor of size <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">-- flatten grasParameters: grad wrt to bias and weights</span><br><span class="line"><span class="number">2.6499e+180</span></span><br><span class="line"> <span class="number">4.9592e+92</span></span><br><span class="line"><span class="number">1.7894e+161</span></span><br><span class="line"><span class="number">1.2806e+213</span></span><br><span class="line">[torch.DoubleTensor of size <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">                                                                      [<span class="number">0.0017</span>s]	</span><br><span class="line">th&gt; linear.output</span><br><span class="line"> <span class="number">0.7441</span></span><br><span class="line">[torch.DoubleTensor of size <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2 id="tensor_get_col:">tensor get col:</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input = torch.Tensor(<span class="number">8</span>,<span class="number">20</span>) -- <span class="number">8</span> rows, <span class="number">20</span> cols</span><br><span class="line">input[<span class="number">1</span>] -- <span class="keyword">return</span> first row</span><br><span class="line">input[&#123;&#123;&#125;, <span class="number">5</span>&#125;] -- <span class="keyword">return</span> the <span class="number">5</span>th col </span><br><span class="line">input[&#123;&#123;&#125;, &#123;<span class="number">4</span>,<span class="number">8</span>&#125;&#125;&#125;] -- <span class="keyword">return</span> the <span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span> col</span><br></pre></td></tr></table></figure>
<h2 id="import_csv">import csv</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line">text_file = <span class="function"><span class="title">open</span><span class="params">(<span class="string">"label.txt"</span>, <span class="string">"w"</span>)</span></span></span><br><span class="line">with <span class="function"><span class="title">open</span><span class="params">(<span class="string">'label.csv'</span> ,<span class="string">'rb'</span>)</span></span> as csvfile:</span><br><span class="line">    reader = csv.<span class="function"><span class="title">reader</span><span class="params">(csvfile)</span></span></span><br><span class="line">    <span class="tag">i</span> = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        name = <span class="string">'imgs/train&#123;:05d&#125;.jpg'</span>.<span class="function"><span class="title">format</span><span class="params">(i)</span></span></span><br><span class="line">        <span class="tag">label</span> = row[<span class="number">0</span>]</span><br><span class="line">        text_file.<span class="function"><span class="title">writelines</span><span class="params">(<span class="string">'%s %s \n'</span> % (name, label)</span></span>)</span><br><span class="line">        <span class="tag">i</span> = <span class="tag">i</span> + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">text_file.<span class="function"><span class="title">close</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<h1 id="minibatch_SGD">minibatch SGD</h1><p>cost function:<br>training + testing<br>parameter updating<br>gradient descent</p>
<p>训练过程有训练步数（n_epoch）的设置，</p>
<p>每个epoch会遍历所有的训练数据（training_set），本程序中也就是320个人脸图。<br>n_epochs训练步数，每一步都会遍历所有batch，即所有样本 </p>
<p>batch_size,这里设置为500，即每遍历完500个样本，才计算梯度并更新参数 </p>
<p>还有迭代次数iter，一次迭代遍历一个batch里的所有样本，具体为多少要看所设置的batch_size。</p>
<h2 id="learning_rate">learning rate</h2><p>设得太大的话算法可能永远都优化不了，设得太小会使算法优化得太慢，而且可能还会掉入局部最优。<br>1) error 一直停在某个值， 可能是学习速率太大， 跳过最优</p>
<h1 id="how_to_save_parameter_in_torch">how to save parameter in torch</h1><h1 id="input_shape(batchsize,_depth,_w,_h)">input shape(batchsize, depth, w, h)</h1><p>SpatialConvolution(depth_origin, depth_update, kh, kw, steph, stepw, padh, pahw)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">nn:add</span><br><span class="line">nn:remove(2)</span><br><span class="line">nn:<span class="operator"><span class="keyword">insert</span>(nn.Spa..., <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- info of the trained network</span></span><br><span class="line">conv_nodes = <span class="keyword">model</span>:findModules(<span class="string">'nn.SpatialConvolution'</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">i</span> = <span class="number">1</span>, #conv_nodes <span class="keyword">do</span></span><br><span class="line">  print(conv_nodes[<span class="keyword">i</span>].<span class="keyword">output</span>:<span class="keyword">size</span>())</span><br><span class="line"><span class="keyword">end</span></span></span><br></pre></td></tr></table></figure>
<p>view is reshape</p>
<p>linear linear transform form R^m to R^n<br>can be used at the final layer of classification, tranform to num or categories</p>
<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- return maximun <span class="keyword">of</span> <span class="number">1</span>d tensor p, <span class="keyword">and</span> its <span class="keyword">index</span></span><br><span class="line">maxi, <span class="keyword">index</span> = torch.max(p, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">-- <span class="keyword">if</span> p <span class="keyword">is</span> (<span class="number">3</span>x5) <span class="keyword">then</span> return maxi <span class="keyword">of</span> <span class="keyword">each</span> cols</span><br><span class="line">maxi <span class="keyword">is</span> <span class="number">1</span>x5 <span class="keyword">and</span> <span class="keyword">index</span> <span class="keyword">is</span> <span class="number">1</span>x5</span><br></pre></td></tr></table></figure>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- lua</span><br><span class="line"><span class="tag">table</span>.<span class="function"><span class="title">getn</span><span class="params">(c)</span></span></span><br></pre></td></tr></table></figure>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// c library <span class="function"><span class="keyword">function</span>:</span></span><br><span class="line">size_t fread(void *ptr, size_t size, size_t nmemb, FILE *stream)</span><br><span class="line"></span><br><span class="line">size: <span class="keyword">bytes</span> <span class="operator">of</span> <span class="keyword">each</span> <span class="keyword">element</span></span><br><span class="line">nmemb: <span class="built_in">number</span> <span class="operator">of</span> elements:</span><br><span class="line"><span class="operator">in</span> total: size*nmemb <span class="keyword">bytes</span></span><br><span class="line"></span><br><span class="line">stream: pointer <span class="built_in">to</span> FILE</span><br></pre></td></tr></table></figure>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">th&gt; <span class="tag">a</span> = torch.<span class="function"><span class="title">data</span><span class="params">(tensor)</span></span></span><br><span class="line">      	</span><br><span class="line">th&gt; <span class="tag">a</span></span><br><span class="line">cdata&lt;double *&gt;: <span class="number">0</span>x022bebe0</span><br></pre></td></tr></table></figure>
<h1 id="read_csv_in_lua">read csv in lua</h1><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">split</span><span class="params">(str, sep)</span></span></span><br><span class="line">    sep = sep <span class="keyword">or</span> <span class="string">','</span></span><br><span class="line">    fields=&#123;&#125;</span><br><span class="line">    <span class="keyword">local</span> matchfunc = <span class="built_in">string</span>.gmatch(str, <span class="string">"([^"</span>..sep..<span class="string">"]+)"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> matchfunc <span class="keyword">then</span> <span class="keyword">return</span> &#123;str&#125; <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">for</span> str <span class="keyword">in</span> matchfunc <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">table</span>.insert(fields, str)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">return</span> fields</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">---------------------------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">read</span><span class="params">(path, sep, tonum)</span></span></span><br><span class="line">    tonum = tonum <span class="keyword">or</span> <span class="keyword">true</span></span><br><span class="line">    sep = sep <span class="keyword">or</span> <span class="string">','</span></span><br><span class="line">    <span class="keyword">local</span> csvFile = &#123;&#125;</span><br><span class="line">    <span class="keyword">local</span> file = <span class="built_in">assert</span>(<span class="built_in">io</span>.open(path, <span class="string">"r"</span>))</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:lines() <span class="keyword">do</span></span><br><span class="line">        fields = split(line, sep)</span><br><span class="line">        <span class="keyword">if</span> tonum <span class="keyword">then</span> <span class="comment">-- convert numeric fields to numbers</span></span><br><span class="line">            <span class="keyword">for</span> i=<span class="number">1</span>,#fields <span class="keyword">do</span></span><br><span class="line">                fields[i] = <span class="built_in">tonumber</span>(fields[i]) <span class="keyword">or</span> fields[i]</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        <span class="built_in">table</span>.insert(csvFile, fields)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    file:close()</span><br><span class="line">    <span class="keyword">return</span> csvFile</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><a href="http://nocurve.com/simple-csv-read-and-write-using-lua/" target="_blank" rel="external">http://nocurve.com/simple-csv-read-and-write-using-lua/</a></p>
<p>batch size 20: all 3 </p>
<h2 id="torch_load_class">torch load class</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dofile</span> <span class="string">'...lua'</span> <span class="comment">-- load the class defined in the file</span></span><br></pre></td></tr></table></figure></span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/logs/" rel="tag">#logs</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/10/17/protocal-buffer/" rel="prev">protocol buffer</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/10/17/caffe-cmd/" rel="next">caffe-cmd</a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

 </div>

        

        
          <div class="comments" id="comments">
            
          </div>
        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table Of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/xx.jpg" alt="XXXH" itemprop="image"/>
          <p class="site-author-name" itemprop="name">XXXH</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">27</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">7</span>
              <span class="site-state-item-name">categories</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">37</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ZENGXH" target="_blank">github</a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#neural_style"><span class="nav-number">1.</span> <span class="nav-text">neural_style</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#count_the_number_of_file"><span class="nav-number">2.</span> <span class="nav-text">count the number of file</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cifar-torch"><span class="nav-number">3.</span> <span class="nav-text">cifar.torch</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#data_processing:"><span class="nav-number">3.1.</span> <span class="nav-text">data processing:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#training"><span class="nav-number">3.2.</span> <span class="nav-text">training</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#screen_command"><span class="nav-number">3.3.</span> <span class="nav-text">screen command</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#environment_variable_affecting_GCC"><span class="nav-number">3.4.</span> <span class="nav-text">environment variable affecting GCC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#setting_shell_configure"><span class="nav-number">3.5.</span> <span class="nav-text">setting shell configure</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#install_blas"><span class="nav-number">3.6.</span> <span class="nav-text">install blas</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#install_torch_without_sodu"><span class="nav-number">3.7.</span> <span class="nav-text">install torch without sodu</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ERROR_lapack"><span class="nav-number">4.</span> <span class="nav-text">ERROR lapack</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#error："><span class="nav-number">4.1.</span> <span class="nav-text">error：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#error:"><span class="nav-number">4.2.</span> <span class="nav-text">error:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#torch_syntax"><span class="nav-number">4.3.</span> <span class="nav-text">torch syntax</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parallel_table:"><span class="nav-number">4.4.</span> <span class="nav-text">parallel table:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#split_table:"><span class="nav-number">4.5.</span> <span class="nav-text">split table:</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#combine:"><span class="nav-number">5.</span> <span class="nav-text">combine:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#net_operation_-_read_para_and_output"><span class="nav-number">6.</span> <span class="nav-text">net operation - read para and output</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#the_simplest_case:_linear_regression:"><span class="nav-number">6.1.</span> <span class="nav-text">the simplest case: linear regression:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensor_get_col:"><span class="nav-number">6.2.</span> <span class="nav-text">tensor get col:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#import_csv"><span class="nav-number">6.3.</span> <span class="nav-text">import csv</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#minibatch_SGD"><span class="nav-number">7.</span> <span class="nav-text">minibatch SGD</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#learning_rate"><span class="nav-number">7.1.</span> <span class="nav-text">learning rate</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#how_to_save_parameter_in_torch"><span class="nav-number">8.</span> <span class="nav-text">how to save parameter in torch</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#input_shape(batchsize,_depth,_w,_h)"><span class="nav-number">9.</span> <span class="nav-text">input shape(batchsize, depth, w, h)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#read_csv_in_lua"><span class="nav-number">10.</span> <span class="nav-text">read csv in lua</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#torch_load_class"><span class="nav-number">10.1.</span> <span class="nav-text">torch load class</span></a></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2015</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XXXH</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  


  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.1" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 0.4 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    var $tocContent = $('.post-toc-content');
    if (isDesktop() && CONFIG.sidebar === 'post') {
      if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
        displaySidebar();
      }
    }
  });
</script>



  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
